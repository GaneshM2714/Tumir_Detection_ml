{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMKdd41KLUN0iCc+UsRyax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaneshM2714/Tumir_Detection_ml/blob/main/Tumor_test_self.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9ZV9ZprrLIW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from os import listdir\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Load images in tumor Array"
      ],
      "metadata": {
        "id": "uFBaIe6PsqE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tumor = []\n",
        "path = \"/content/no/*.*\"\n",
        "\n",
        "for i in glob.glob(path):\n",
        "  img = cv2.imread(i)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  tumor.append(img)\n",
        "\n",
        "path = \"/content/yes/*.*\"\n",
        "\n",
        "for i in glob.glob(path):\n",
        "  img = cv2.imread(i)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  tumor.append(img)\n",
        "\n",
        "print(len(tumor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBNlFRPQrhkt",
        "outputId": "a623f58e-e566-4c17-a2fd-ff1170db6e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_brain_contour(image, plot=False):\n",
        "\n",
        "    #import imutils\n",
        "    #import cv2\n",
        "    #from matplotlib import pyplot as plt\n",
        "\n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Threshold the image, then perform a series of erosions +\n",
        "    # dilations to remove any small regions of noise\n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    # Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\n",
        "    # Find the extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\n",
        "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]\n",
        "\n",
        "    if plot:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image)\n",
        "\n",
        "        plt.tick_params(axis='both', which='both',\n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(new_image)\n",
        "\n",
        "        plt.tick_params(axis='both', which='both',\n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "        plt.title('Cropped Image')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "GoMfg_wlsphs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_img = cv2.imread('/content/yes/Y1.jpg')\n",
        "ex_new_img = crop_brain_contour(ex_img, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "h5TSZssyuLsV",
        "outputId": "61cc2cb0-9a99-47cd-86ed-24da8d7b1f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-715695941efe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mex_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yes/Y1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mex_new_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_brain_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-acac6ff41d23>\u001b[0m in \u001b[0;36mcrop_brain_contour\u001b[0;34m(image, plot)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Convert the image to grayscale, and blur it slightly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dirlist,img_size):\n",
        "    \"\"\"\n",
        "    Read images, resize and normalize them.\n",
        "    Arguments:\n",
        "        dir_list: list of strings representing file directories.\n",
        "    Returns:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    image_width, image_height = img_size\n",
        "\n",
        "    for directory in dirlist:\n",
        "        for filename in (os.listdir(directory)):\n",
        "            # load the image\n",
        "            img = cv2.imread(os.path.join(directory,filename))\n",
        "            image = crop_brain_contour(img, plot=False)\n",
        "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
        "            image = image / 255.\n",
        "            X.append(image)\n",
        "\n",
        "            if(directory[-3:] == 'yes'):\n",
        "                y.append([1])\n",
        "            else:\n",
        "                y.append([0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    X,y = shuffle(X,y)\n",
        "    print(f'Number of examples is: {len(X)}')\n",
        "    print(f'X shape is: {X.shape}')\n",
        "    print(f'y shape is: {y.shape}')\n",
        "\n",
        "    return X, y\n",
        "\n"
      ],
      "metadata": {
        "id": "cuBgN6E6w23c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X, y = load_data(['/content/yes', '/content/no'], (240, 240))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "dWMPvCU4w4yF",
        "outputId": "5847f5fe-957e-441e-9cc0-ef4b04ce0f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/yes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1d0e08b689a1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/content/yes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/no'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-cd2ae77e9f68>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dirlist, img_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample_images(X, y, n=50):\n",
        "    \"\"\"\n",
        "    Plots n sample images for both values of y (labels).\n",
        "    Arguments:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    for label in [0,1]:\n",
        "        # grab the first n images with the corresponding y values equal to label\n",
        "        images = X[np.argwhere(y == label)]\n",
        "        n_images = images[:n]\n",
        "\n",
        "        columns_n = 10\n",
        "        rows_n = int(n/ columns_n)\n",
        "\n",
        "        plt.figure(figsize=(20, 10))\n",
        "\n",
        "        i = 1 # current plot\n",
        "        for image in n_images:\n",
        "            plt.subplot(rows_n, columns_n, i)\n",
        "            plt.imshow(image[0])\n",
        "\n",
        "            # remove ticks\n",
        "            plt.tick_params(axis='both', which='both',\n",
        "                            top=False, bottom=False, left=False, right=False,\n",
        "                           labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        label_to_str = lambda label: \"Yes\" if label == 1 else \"No\"\n",
        "        plt.suptitle(f\"Brain Tumor: {label_to_str(label)}\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "p7pY0LVjw4uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample_images(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "mWggfzKtw4r6",
        "outputId": "f4245063-098e-4785-aaac-04b5d7db84e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-97bc5e4585b3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_sample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X, y, test_size=0.2):\n",
        "\n",
        "    \"\"\"\n",
        "    Splits data into training, development and test sets.\n",
        "    Arguments:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    Returns:\n",
        "        X_train: A numpy array with shape = (#_train_examples, image_width, image_height, #_channels)\n",
        "        y_train: A numpy array with shape = (#_train_examples, 1)\n",
        "        X_val: A numpy array with shape = (#_val_examples, image_width, image_height, #_channels)\n",
        "        y_val: A numpy array with shape = (#_val_examples, 1)\n",
        "        X_test: A numpy array with shape = (#_test_examples, image_width, image_height, #_channels)\n",
        "        y_test: A numpy array with shape = (#_test_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
        "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "metadata": {
        "id": "V9XQs5zRw4pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "eW-XYd1jw4mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of development examples = \" + str(X_val.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(y_train.shape))\n",
        "print (\"X_val (dev) shape: \" + str(X_val.shape))\n",
        "print (\"Y_val (dev) shape: \" + str(y_val.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(y_test.shape))"
      ],
      "metadata": {
        "id": "1cOsxq43w4kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Segmentation Try"
      ],
      "metadata": {
        "id": "kWhEJezx8gki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net Architecture\n",
        "def unet_model(input_size=(240, 240, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder (Downsampling)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # Bottleneck\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Dropout(0.3)(c4)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    # Decoder (Upsampling)\n",
        "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = concatenate([u5, c3])\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = Dropout(0.2)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c2])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Dropout(0.1)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c1])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Dropout(0.1)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "exCITlSl7YvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Paths to the images and corresponding masks\n",
        "image_path = \"/content/yes/*.jpg\"  # Adjust to match your image format\n",
        "mask_path = \"/content/tumor_masks/*.png\"\n",
        "\n",
        "# Load and resize images and masks\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "for img_path in glob.glob(image_path):\n",
        "    img = cv2.imread(img_path)  # Read the image\n",
        "    img = cv2.resize(img, (224, 224))  # Resize to 224x224 (consistent with the model)\n",
        "    images.append(img)\n",
        "\n",
        "for mask_path in glob.glob(mask_path):\n",
        "    mask = cv2.imread(mask_path, 0)  # Read the mask in grayscale\n",
        "    mask = cv2.resize(mask, (224, 224))  # Resize to 224x224\n",
        "    mask = np.expand_dims(mask, axis=-1)  # Add a channel dimension (H, W, 1)\n",
        "    masks.append(mask)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)\n",
        "\n",
        "# Normalize images and masks\n",
        "images = images / 255.0  # Normalize image values to [0, 1]\n",
        "masks = masks / 255.0  # Masks should be binary (0 or 1)\n"
      ],
      "metadata": {
        "id": "fJBqBjrm8t4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the U-Net model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yw4h_C5Y7gZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# **Initiation of Building Convolutional Neural Network**\n"
      ],
      "metadata": {
        "id": "xiGtrETbw4hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9hzpSMFw4e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZcScn9CMw4cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_U34UU4kw4Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-5xsok9w4XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3WGbypcw4Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpeKjlAZw4R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gr1ka8Lmw4PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IptV_6ow4MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qGh0LGrjw4ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUx4O0XOw3_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ynf1_jk-w33C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-ainNqZw3tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XXIaDIyw3iD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}